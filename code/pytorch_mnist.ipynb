{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tecBWNELRYYj"
      },
      "source": [
        "# The complete training and evaluation process with PyTorch\n",
        "\n",
        "## 學習目標\n",
        "- 我們已經學過 Gradient Descent, Backpropagation, 以及更進階的梯度下降最佳化方法 (如 SGD, Adam 等)\n",
        "- 因此我們接下來要實作一個完整的神經網路訓練流程，同時也將介紹評估流程"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9bVK2wRBSVPm"
      },
      "source": [
        "## 測試現在這個 Colab 環境是否已經使用 GPU\n",
        "- 否則等下可能會需要重新啟動 Colab 環境"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G4pZ2YqXRT_B",
        "outputId": "235ff35f-73ef-4e99-a5b3-75d4e9f99b0d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import torch\n",
        "torch.cuda.is_available() # 結果需要顯示為 True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gEFJ2Wb7S5cw"
      },
      "source": [
        "## PyTorch 常用套件\n",
        "\n",
        "| 套件名稱 | 主要內容 |\n",
        "|-|-|\n",
        "|[`torch.nn as nn`](https://pytorch.org/docs/stable/nn.html) | 與模型架構相關的函數，包含各種層與目標函數的實作 |\n",
        "|[`torch.optim`](https://pytorch.org/docs/stable/optim.html) | 與模型最佳化有相關的函數 (optim: optimization) |\n",
        "|[`torchvision`](https://pytorch.org/vision/stable/index.html) | 與電腦視覺 (影像) 任務有相關的函數 |\n",
        "|[`torchvision.transforms`](https://pytorch.org/vision/0.9/transforms.html) | 幫助進行影像資料前處理的函數 |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VLATNhzVRaLa"
      },
      "outputs": [],
      "source": [
        "# 引入本教學所需要的套件\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8JvjHfnmm5Fr"
      },
      "source": [
        "## 載入資料\n",
        "- 本教學使用的是 MNIST 手寫字辨識資料集 (by [Yann LeCun](http://yann.lecun.com/exdb/mnist/))\n",
        "\n",
        "![MNIST](https://upload.wikimedia.org/wikipedia/commons/b/b1/MNIST_dataset_example.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g3eIzz6Zm5Fs"
      },
      "source": [
        "## 觀察資料"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4BrWEENOm5Fu",
        "outputId": "7782c302-8b0a-4af3-dd93-c37af77e53c7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 18.3MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 492kB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 4.54MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 8.19MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "image 的資料格式為: <class 'PIL.Image.Image'>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# 載入 MNIST 資料\n",
        "# `train=False` 代表載入 test 資料\n",
        "tmp = torchvision.datasets.MNIST(root=\"./data\", train=False, download=True)\n",
        "\n",
        "# 取得第一張圖片和標籤\n",
        "image, label = tmp[0]\n",
        "print(f\"image 的資料格式為: {type(image)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "suMsFPJwm5Fu",
        "outputId": "9fdd3baa-dc80-48c8-95d9-9bd00a7e6ccd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 45
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAzUlEQVR4AWNgGDaAEeKTkNRnP5a+uIPmLajkPQWg+OerUMknXWfALBYIP1X/mpahg8VjWQaGP68lGR5BJKE6wUoEDc+YMjD8uHVdKGca1AwMKvjvRSEMQaiA2Mv/wVAmE4aabNH3NzEEoQLWP//Z4ZJjaP23mxWXJOfZH1a45Bjq/m3DKef9+4MlLknhu/+W4ZJjPv3vtjIuSbV//3xxyck/+FeMHNYo6lr//TNBEUDi2H5Cl0QKWxsehrtfkBQzMEAjGyJ20fkdiiReDgBpETyQooNMkwAAAABJRU5ErkJggg==\n",
            "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/wAALCAAcABwBAREA/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/9oACAEBAAA/APA4Lea6nSC3hkmmc4SONSzMfQAdadc2dzZSmK7tpoJB/BKhU/kahoq1pupXuj6hDf6dcyW13CSY5YzhlyCDj8CRXXWvxe8b20SxtrH2lVOQbqCOU9OmWUn/APVXUfEfxBqCfDzSNJ16S2uNd1JxqEqpbohtIMYjQbQBlsEnv1HpXj9Fdx8OvDNlqNxe+IdeVh4e0VPPucLnznyNkQ/3j1/LjOa57xPr9z4n8R3usXQ2vcSZVB0jQcKo9gABWRRXSxeOdXt/A0nhGAW0WnSzGaZ1j/ey8g7SxOMZA6AHjrXNUV//2Q==\n"
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "# Jupyter Notebook 內建支援顯示 PIL 影像\n",
        "# 所以直接輸入在程式格中執行後會自動顯示原始影像\n",
        "\n",
        "image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Fwej25Xm5Fw",
        "outputId": "c875cd34-5073-479e-8906-3221b41e544d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7e4d44f79ac0>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# maplotlib 的 imshow 功能可以顯示 PIL 影像\n",
        "# 但如果是灰階影像的話，它會幫套上 colormap，所以看起來很像彩色影像\n",
        "\n",
        "plt.imshow(image)\n",
        "# plt.imshow(image, cmap=\"gray\") # 若資料是灰階影像，應加上 cmap=\"gray\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "asZDvkxploWa",
        "outputId": "7c9fbab3-b27f-4aba-b773-dda59f04a9b5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "image 的資料格式為: <class 'torch.Tensor'>\n"
          ]
        }
      ],
      "source": [
        "# 觀察有進行 ToTensor() 後的資料\n",
        "transform = transforms.Compose(\n",
        "    [\n",
        "        transforms.ToTensor(),\n",
        "    ]\n",
        ")\n",
        "trainset = torchvision.datasets.MNIST(\n",
        "    root='./data',\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=transform,\n",
        ")\n",
        "\n",
        "# 取得第一張圖片和標籤\n",
        "image, label = trainset[0]\n",
        "print(f\"image 的資料格式為: {type(image)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "amxP7s3JnVaY",
        "outputId": "1f394e7e-dd26-4363-cf72-eb995eab3685"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 28, 28])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "image.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "id": "vce_8r-ZmP_R",
        "outputId": "9a10497f-06d4-43cb-b46c-7e3ae6a5517c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7e4d44f45fd0>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "plt.imshow(image.squeeze(), cmap=\"gray\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RwjBaXTDm5Fw"
      },
      "source": [
        "## 建立模型"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_NAME = \"resnet-18\" # or \"resnet-18"
      ],
      "metadata": {
        "id": "--4Nvhy6S6kN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eAG97vIumtRO"
      },
      "outputs": [],
      "source": [
        "# 定義 MLP 模型\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__() # 繼承 nn.Module 類別的初始化函數\n",
        "        hidden_size1 = 256 # 第一層隱藏層的神經元數量\n",
        "        hidden_size2 = 128 # 第二層隱藏層的神經元數量\n",
        "\n",
        "        self.layer_1 = nn.Linear(28*28, hidden_size1)\n",
        "        self.layer_2 = nn.Linear(256, hidden_size2)\n",
        "        self.relu = nn.ReLU() # 非線性轉換\n",
        "        self.cls_layer = nn.Linear(hidden_size2, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 28*28) # 將輸入的 x 轉為 28*28 的形狀 (因為 transform.ToTensor() 會把圖片轉為 1*28*28)\n",
        "        x = self.relu(self.layer_1(x))\n",
        "        x = self.relu(self.layer_2(x))\n",
        "        x = self.cls_layer(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 初始化模型\n",
        "\n",
        "if MODEL_NAME == \"resnet-18\":\n",
        "    model = torchvision.models.resnet18(pretrained=True)\n",
        "    model.fc = nn.Linear(512, 10)\n",
        "elif MODEL_NAME == \"MLP\":\n",
        "    model = MLP()\n",
        "else:\n",
        "    raise NotImplementedError"
      ],
      "metadata": {
        "id": "lw8-cVSzYB-_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae15165d-5126-43dd-8e40-d045abfbccb7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 139MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "seLgDhA9Udm2"
      },
      "outputs": [],
      "source": [
        "# 載入 MNIST 資料並進行影像前處理\n",
        "# PyTorch 官方範例連結：https://github.com/pytorch/examples/blob/main/mnist_forward_forward/main.py#L160C23-L160C43\n",
        "\n",
        "# 資料前處理管線\n",
        "if MODEL_NAME == \"resnet-18\":\n",
        "    transform = transforms.Compose(\n",
        "        [\n",
        "            transforms.Resize((224, 224)),\n",
        "            transforms.Grayscale(num_output_channels=3),  # 把 1-channel 轉成 3-channel\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "        ]\n",
        "    )\n",
        "elif MODEL_NAME == \"MLP\":\n",
        "    transform = transforms.Compose([transforms.ToTensor(),])\n",
        "else:\n",
        "    raise NotImplementedError\n",
        "\n",
        "\n",
        "# 載入 MNIST 資料\n",
        "# `train=False` 代表載入 test 資料\n",
        "trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "testset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7B4s0T5PW7Lh",
        "outputId": "ea4ae96c-cd5d-427d-92e4-940cfd7a8caa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MNIST 訓練資料有 60000 筆\n",
            "MNIST 測試資料有 10000 筆\n"
          ]
        }
      ],
      "source": [
        "print(f\"MNIST 訓練資料有 {len(trainset)} 筆\")\n",
        "print(f\"MNIST 測試資料有 {len(testset)} 筆\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DGdJJvVhm5Fx"
      },
      "source": [
        "## 將資料分裝成 batches\n",
        "- 假設我們有一個資料集，進行機器學習時，我們會將資料分為：\n",
        "    - **訓練資料 (training data)**：用來訓練模型\n",
        "    - **驗證資料 (validation data)**：在訓練訓練階段，我們可能訓練了多個模型，要知道哪個模型是最好的則需要對模型進行測試，在模型訓練階段用以測試模型的資料我們稱為「驗證資料」\n",
        "    - **測試資料 (test data)**：完成模型訓練後，用來檢視模型真正成效的資料\n",
        "- 一般來說，我們會將訓練資料打亂 (`shuffle=True`)，驗證/測試資料不打亂\n",
        "- 我們可以使用 Scikit-learn 的 [`train_test_split`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) 來進行資料切分"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "azl0H9Aum5Fy"
      },
      "outputs": [],
      "source": [
        "# 把 validation set 從 training set 切出來 10%\n",
        "# random_state: Pass an int for reproducible output\n",
        "\n",
        "N = len(trainset)\n",
        "indices = torch.arange(N)\n",
        "\n",
        "train_idx, val_idx = train_test_split(\n",
        "    indices.numpy(),\n",
        "    test_size=0.1,\n",
        "    random_state=42,\n",
        ")\n",
        "\n",
        "trainset_sub = torch.utils.data.Subset(trainset, train_idx)\n",
        "valset   = torch.utils.data.Subset(trainset, val_idx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O6qFr1Dtm5Fy",
        "outputId": "676c1361-b354-4e80-9e08-dcd35d798c1d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MNIST 訓練資料有 60000 筆\n",
            "MNIST 訓練資料有 6000 筆\n",
            "MNIST 測試資料有 10000 筆\n"
          ]
        }
      ],
      "source": [
        "print(f\"MNIST 訓練資料有 {len(trainset)} 筆\")\n",
        "print(f\"MNIST 訓練資料有 {len(valset)} 筆\")\n",
        "print(f\"MNIST 測試資料有 {len(testset)} 筆\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eFNlLA6Uonga"
      },
      "outputs": [],
      "source": [
        "train_loader = torch.utils.data.DataLoader(\n",
        "    trainset_sub,\n",
        "    batch_size=64,\n",
        "    shuffle=True,\n",
        ")\n",
        "val_loader = torch.utils.data.DataLoader(\n",
        "    valset,\n",
        "    batch_size=256,\n",
        "    shuffle=False,\n",
        ")\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    testset,\n",
        "    batch_size=256,\n",
        "    shuffle=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7dJUm1qbm5Fy"
      },
      "source": [
        "## 取得 DataLoader 中的一個 Batch\n",
        "- 在 PyTorch 中，`DataLoader` 是一個 **可迭代對象 (iterable)**\n",
        "- 我們可以使用 **`iter()`** 和 **`next()`** 來手動取得一個 batch：\n",
        "```python\n",
        "images, labels = next(iter(train_loader))\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gKxY2fGCovOp",
        "outputId": "eee4f31e-d143-49eb-db4e-8e4d52a17f12"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "          ...,\n",
            "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "          [-1., -1., -1.,  ..., -1., -1., -1.]],\n",
            "\n",
            "         [[-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "          ...,\n",
            "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "          [-1., -1., -1.,  ..., -1., -1., -1.]],\n",
            "\n",
            "         [[-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "          ...,\n",
            "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "          [-1., -1., -1.,  ..., -1., -1., -1.]]],\n",
            "\n",
            "\n",
            "        [[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "          ...,\n",
            "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "          [-1., -1., -1.,  ..., -1., -1., -1.]],\n",
            "\n",
            "         [[-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "          ...,\n",
            "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "          [-1., -1., -1.,  ..., -1., -1., -1.]],\n",
            "\n",
            "         [[-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "          ...,\n",
            "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "          [-1., -1., -1.,  ..., -1., -1., -1.]]],\n",
            "\n",
            "\n",
            "        [[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "          ...,\n",
            "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "          [-1., -1., -1.,  ..., -1., -1., -1.]],\n",
            "\n",
            "         [[-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "          ...,\n",
            "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "          [-1., -1., -1.,  ..., -1., -1., -1.]],\n",
            "\n",
            "         [[-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "          ...,\n",
            "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "          [-1., -1., -1.,  ..., -1., -1., -1.]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "          ...,\n",
            "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "          [-1., -1., -1.,  ..., -1., -1., -1.]],\n",
            "\n",
            "         [[-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "          ...,\n",
            "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "          [-1., -1., -1.,  ..., -1., -1., -1.]],\n",
            "\n",
            "         [[-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "          ...,\n",
            "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "          [-1., -1., -1.,  ..., -1., -1., -1.]]],\n",
            "\n",
            "\n",
            "        [[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "          ...,\n",
            "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "          [-1., -1., -1.,  ..., -1., -1., -1.]],\n",
            "\n",
            "         [[-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "          ...,\n",
            "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "          [-1., -1., -1.,  ..., -1., -1., -1.]],\n",
            "\n",
            "         [[-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "          ...,\n",
            "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "          [-1., -1., -1.,  ..., -1., -1., -1.]]],\n",
            "\n",
            "\n",
            "        [[[-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "          ...,\n",
            "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "          [-1., -1., -1.,  ..., -1., -1., -1.]],\n",
            "\n",
            "         [[-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "          ...,\n",
            "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "          [-1., -1., -1.,  ..., -1., -1., -1.]],\n",
            "\n",
            "         [[-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "          ...,\n",
            "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "          [-1., -1., -1.,  ..., -1., -1., -1.],\n",
            "          [-1., -1., -1.,  ..., -1., -1., -1.]]]])\n",
            "tensor([9, 5, 8, 8, 3, 0, 2, 0, 1, 1, 6, 7, 4, 6, 0, 3, 6, 3, 9, 2, 7, 1, 7, 1,\n",
            "        9, 5, 5, 8, 6, 1, 0, 6, 3, 3, 7, 9, 0, 6, 9, 9, 0, 1, 6, 7, 9, 9, 7, 2,\n",
            "        1, 3, 0, 1, 4, 7, 9, 2, 3, 5, 1, 1, 9, 6, 0, 8])\n",
            "torch.Size([64, 3, 224, 224])\n",
            "torch.Size([64])\n"
          ]
        }
      ],
      "source": [
        "# 觀察 batches 資料\n",
        "\n",
        "train_iter = iter(train_loader)  # 取得迭代器\n",
        "batch_x, batch_y = next(train_iter) # 取出一個 batch\n",
        "print(batch_x)\n",
        "print(batch_y)\n",
        "print(batch_x.shape)\n",
        "print(batch_y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YXRE6dJmm5Fz",
        "outputId": "f6c7d17f-adc8-418f-a9dc-36d9cb310afe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([2, 6, 3, 2, 9, 7, 1, 3, 5, 9, 8, 9, 8, 9, 8, 3, 6, 5, 1, 8, 7, 9, 6, 3,\n",
            "        5, 8, 2, 4, 0, 4, 8, 4, 7, 7, 6, 6, 7, 2, 1, 5, 0, 8, 8, 0, 4, 5, 4, 3,\n",
            "        4, 7, 3, 4, 7, 1, 2, 8, 7, 6, 9, 8, 4, 1, 0, 5])\n",
            "torch.Size([64])\n"
          ]
        }
      ],
      "source": [
        "# 每次進行 next() 就會取得下一次的迭代\n",
        "\n",
        "_, batch_y = next(train_iter) # 這邊就單純觀察 y 就好\n",
        "print(batch_y)\n",
        "print(batch_y.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Helper functions"
      ],
      "metadata": {
        "id": "Px6hG_iyO-B1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_epoch(\n",
        "    model: nn.Module,\n",
        "    data_loader: torch.utils.data.DataLoader,\n",
        "    optimizer: torch.optim.Optimizer,\n",
        "    loss_fn: torch.nn.Module,\n",
        "    device: torch.device,\n",
        "):\n",
        "    \"\"\"\n",
        "    執行一個訓練 epoch 的函式\n",
        "    \"\"\"\n",
        "    model.train() # 確保 model 是在訓練模式\n",
        "    total_loss = 0 # 紀錄 loss 數值\n",
        "\n",
        "    progress_bar = tqdm(data_loader, desc=\"Training\")\n",
        "    for batch in progress_bar:\n",
        "        # 把資料移動到 GPU\n",
        "        images, labels = batch[0].to(device), batch[1].to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # 1. 前向傳播\n",
        "        outputs = model(images)\n",
        "        loss = loss_fn(outputs, labels)\n",
        "\n",
        "        # 2. 反向傳播 (計算梯度)\n",
        "        loss.backward()\n",
        "\n",
        "        # 3. 更新模型權重\n",
        "        optimizer.step()\n",
        "\n",
        "        # 儲存 loss 數值\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        progress_bar.set_postfix({\n",
        "            'loss': f\"{total_loss / (progress_bar.n + 1):.4f}\",\n",
        "        })\n",
        "    return total_loss / len(data_loader) # 回傳平均每筆資料的 loss"
      ],
      "metadata": {
        "id": "HDC9thMEDMRx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dsb0cvRrm5F0"
      },
      "source": [
        "### 計算分數\n",
        "- 我們可以使用 Scikit-learn 的 [`accuracy_score`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html) 來幫我們計算準確率 (Accuracy)：\n",
        "```python\n",
        "sklearn.metrics.accuracy_score(y_true, y_pred, *, normalize=True, sample_weight=None)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def do_eval(\n",
        "    model: nn.Module,\n",
        "    data_loader: torch.utils.data.DataLoader,\n",
        "    loss_fn: torch.nn.Module,\n",
        "    device: torch.device,\n",
        "):\n",
        "    \"\"\"\n",
        "    執行一個評估 epoch 的函式\n",
        "    \"\"\"\n",
        "    model.eval() # 確保 model 是在評估模式\n",
        "    total_loss = 0 # 紀錄 loss 數值\n",
        "    label_list = []\n",
        "    prediction_list = []\n",
        "\n",
        "    progress_bar = tqdm(data_loader, desc=\"Evaluating\")\n",
        "    with torch.no_grad():\n",
        "        for batch in progress_bar:\n",
        "            images, labels = batch[0].to(device), batch[1].to(device)\n",
        "            outputs = model(images) # `outputs` 的形狀是 (batch_size, 10)\n",
        "            # print(outputs.shape)\n",
        "            loss = loss_fn(outputs, labels)\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            prediction = outputs.argmax(dim=1) # `prediction` 的型態是 tensor\n",
        "\n",
        "            # 我們希望 `predictions` 的長相是 [1, 2, 0, 4, 5, 7, ...]\n",
        "            # 如果用 append 的話可能會變成 [[1, 2, 0], [4, 5, 7], ...]\n",
        "            prediction_list.extend(prediction.tolist())\n",
        "\n",
        "            label_list.extend(labels.tolist())\n",
        "\n",
        "    avg_loss = total_loss / len(data_loader)\n",
        "    accuracy = accuracy_score(label_list, prediction_list)\n",
        "    return avg_loss, accuracy, label_list, prediction_list"
      ],
      "metadata": {
        "id": "SKaBp90LEmri"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4PZi3GkEm5Fz"
      },
      "source": [
        "## 訓練模型"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nDAzYVwOoKLc"
      },
      "outputs": [],
      "source": [
        "# 設定設備\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TwXlhJe9m5Fz"
      },
      "outputs": [],
      "source": [
        "# 初始化模型、損失函數、optimizer\n",
        "\n",
        "model.to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "id": "umIWbv-JoQ7r",
        "outputId": "d2b3c338-2937-4b61-bacd-5608c315eb28"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 844/844 [04:18<00:00,  3.27it/s, loss=0.0685]\n",
            "Evaluating: 100%|██████████| 24/24 [00:17<00:00,  1.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1/10 | Train Loss: 0.0685 | Val Loss: 0.0718 | Val Acc: 0.9788\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   5%|▌         | 46/844 [00:14<04:05,  3.25it/s, loss=0.0261]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1061981942.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     train_loss_epoch = train_epoch(\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mdata_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3901162966.py\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(model, data_loader, optimizer, loss_fn, device)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;31m# 儲存 loss 數值\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         progress_bar.set_postfix({\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# 訓練模型\n",
        "\n",
        "epochs = 10 # MLP 可以訓練久一點，ResNet-18 只需要 1 個 epoch就夠了\n",
        "train_losses, val_losses = [], []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    train_loss_epoch = train_epoch(\n",
        "        model=model,\n",
        "        data_loader=train_loader,\n",
        "        optimizer=optimizer,\n",
        "        loss_fn=criterion,\n",
        "        device=device,\n",
        "    )\n",
        "    train_losses.append(train_loss_epoch)\n",
        "\n",
        "    # 驗證模型\n",
        "    val_loss, val_acc, _, _ = do_eval(\n",
        "        model=model,\n",
        "        data_loader=val_loader,\n",
        "        loss_fn=criterion,\n",
        "        device=device,\n",
        "    )\n",
        "    val_losses.append(val_loss)\n",
        "\n",
        "    print()\n",
        "    print(f\"Epoch {epoch+1}/{epochs} | Train Loss: {train_loss_epoch:.4f} | Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 測試訓練完的模型"
      ],
      "metadata": {
        "id": "cL9AglMDPHlF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ShLm9kpsm5F0"
      },
      "outputs": [],
      "source": [
        "# 測試訓練完的模型\n",
        "test_loss, test_acc, _, _ = do_eval(\n",
        "    model=model,\n",
        "    data_loader=test_loader,\n",
        "    loss_fn=criterion,\n",
        "    device=device,\n",
        ")\n",
        "print()\n",
        "print(f\"Test Loss: {test_loss:.4f} | Test Acc: {test_acc:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_loss_history(train_losses: list, val_losses: list):\n",
        "    \"\"\"\n",
        "    繪製訓練過程的 Training Loss 和 Validation Loss 曲線。\n",
        "\n",
        "    Args:\n",
        "        train_losses (list): 訓練集的 loss 歷史記錄。\n",
        "        val_losses (list): 驗證集的 loss 歷史記錄。\n",
        "    \"\"\"\n",
        "    # 繪製 loss 的歷史記錄圖\n",
        "    plt.plot(range(1, epochs+1), train_losses, label='Train Loss')\n",
        "    plt.plot(range(1, epochs+1), val_losses, label='Validation Loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.xlim([1, epochs])\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.title('Training and Validation Loss')\n",
        "    plt.show()\n",
        "\n",
        "plot_loss_history(train_losses, val_losses)"
      ],
      "metadata": {
        "id": "bQ3rq9r2RJ53"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "base"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}