# Week 3 Quiz
## Q1 (本來要考但沒考)
請簡單說明 Forward Pass 和 Backward Pass 的差別。
（提示：Forward Pass 做什麼？Backward Pass 又在做什麼？
### Answer
- Forward Pass: 將輸入資料經由神經網路的層層運算，產生最終輸出
- Backward Pass: 使用 Chain rule，將 loss 對參數的梯度從輸出層由後往前計算

## Q2
在梯度下降 (Gradient Descent) 中，「梯度」代表什麼意思？
（單維情況 vs 多維情況，可以只寫其中一個）
### Answer
- 在單維度時，梯度代表函數在某一點的變化率，或是函數在該點的切線斜率。
- 在多維度時，梯度為向量形式，梯度的大小，也就是梯度的範數 $|∇_x 𝑓|$，同樣表示函數在該點的變化率。

## Q3
```
A =  [
        [1, 2],
        [3, 4],
        [5, 6],
    ]

B = [
        [1],
        [-1],
        [1]
    ]
```
請問如果以NumPy來計算，A+B的結果是？

### Answer
```python
>>> a+b
array([[2, 3],
       [2, 3],
       [6, 7]])
```